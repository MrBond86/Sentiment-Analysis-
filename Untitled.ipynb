{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b19e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\junki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\junki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c10213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import flask\n",
    "import pickle\n",
    "from string import Template\n",
    "from flask import Flask, redirect, url_for, request, render_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd9d0019",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__, template_folder='templates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b87debe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "@app.route('/index')\n",
    "def index():\n",
    "    return flask.render_template('index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e47bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162980\n"
     ]
    }
   ],
   "source": [
    "all_tweets = pd.read_csv(r\"C:/Users/junki/Desktop/Twitter_Data.csv\")\n",
    "print(len(all_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64527d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         when modi promised “minimum government maximum...\n",
      "1         talk all the nonsense and continue all the dra...\n",
      "2         what did just say vote for modi  welcome bjp t...\n",
      "3         asking his supporters prefix chowkidar their n...\n",
      "4         answer who among these the most powerful world...\n",
      "                                ...                        \n",
      "162975    why these 456 crores paid neerav modi not reco...\n",
      "162976    dear rss terrorist payal gawar what about modi...\n",
      "162977    did you cover her interaction forum where she ...\n",
      "162978    there big project came into india modi dream p...\n",
      "162979    have you ever listen about like gurukul where ...\n",
      "Name: clean_text, Length: 162980, dtype: object\n",
      "when modi promised “minimum government maximum governance” expected him begin the difficult job reforming the state why does take years get justice state should and not business and should exit psus and temples\n"
     ]
    }
   ],
   "source": [
    "dtype = (all_tweets[\"clean_text\"])\n",
    "print(dtype)\n",
    "\n",
    "dd = all_tweets['clean_text'].tolist()\n",
    "print((dd[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35556d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55213\n",
      "1         talk all the nonsense and continue all the dra...\n",
      "5                  kiya tho refresh maarkefir comment karo \n",
      "6         surat women perform yagna seeks divine grace f...\n",
      "7         this comes from cabinet which has scholars lik...\n",
      "13        one vote can make all the difference anil kapo...\n",
      "                                ...                        \n",
      "162968    case dont look candidate then that case person...\n",
      "162971    congress veteran sudhakar reddy joins bjp afte...\n",
      "162974    save your agenda peddling ’ had with terror at...\n",
      "162977    did you cover her interaction forum where she ...\n",
      "162978    there big project came into india modi dream p...\n",
      "Name: clean_text, Length: 55213, dtype: object\n",
      "72250\n",
      "35510\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "all_netural_tweets = all_tweets[all_tweets.category == 0]\n",
    "print(len(all_netural_tweets))\n",
    "\n",
    "all_netural_tweets = all_netural_tweets.loc[:,'clean_text']\n",
    "print((all_netural_tweets))\n",
    "\n",
    "#all_netural_tweets = all_netural_tweets.to_json(orient = 'split')\n",
    "\n",
    "\n",
    "all_positive_tweets = all_tweets[all_tweets.category == 1]\n",
    "print(len(all_positive_tweets))\n",
    "\n",
    "all_positive_tweets = all_positive_tweets.loc[:,'clean_text']\n",
    "\n",
    "all_negative_tweets = all_tweets[all_tweets.category == -1]\n",
    "print(len(all_negative_tweets))\n",
    "\n",
    "all_negative_tweets = all_negative_tweets.loc[:,'clean_text']\n",
    "\n",
    "print(type(all_netural_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb48f0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "talk all the nonsense and continue all the drama will vote for modi \n",
      "kiya tho refresh maarkefir comment karo \n",
      "surat women perform yagna seeks divine grace for narendra modi become again\n",
      "\n",
      "this comes from cabinet which has scholars like modi smriti and hema time introspect\n",
      "one vote can make all the difference anil kapoor answers modis election 2019 clarion call extends support his vote kar campaign \n",
      "one vote can make all the difference anil kapoor answers modis election 2019 clarion call extends support his campaign \n",
      "vote modi who has not created jobs\n",
      "through our vote ensure govt need and deserve anupam kher responds modis appeal for the 2019 elections \n",
      "crush jaws those who shoutmodimodi says jds mla this inciting murder\n",
      "has already taken notice and ordered probe now time for modi take notice muslim family being harassed beaten recently extremist hindus and was suggested leave india move pakistan\n"
     ]
    }
   ],
   "source": [
    "all_netural_tweets = all_netural_tweets.values.tolist()\n",
    "print(type(all_netural_tweets))\n",
    "\n",
    "for x in range(10):\n",
    "    print(all_netural_tweets[x])\n",
    "\n",
    "all_positive_tweets = all_positive_tweets.values.tolist()\n",
    "\n",
    "all_negative_tweets = all_negative_tweets.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f9a221e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 235 3980  905 ... 4182 2318  271]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "rand = np.random.randint(0,5000,4000)\n",
    "print(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5db82885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0048aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "  stemmer = PorterStemmer() \n",
    "  stopwords_english = stopwords.words('english')\n",
    "\n",
    "  # remove the stock market tickers\n",
    "  tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "\n",
    "  # remove the old styles retweet text 'RT'\n",
    "  tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "\n",
    "  # remove the hyperlinks\n",
    "  tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "\n",
    "  # remove the # symbol\n",
    "  tweet = re.sub(r'#', '', tweet)\n",
    "\n",
    "  # Tokenize the tweet\n",
    "  tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "  tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "  tweet_clean = []\n",
    "\n",
    "  # removing stopwords and punctuation\n",
    "  for word in tweet_tokens:\n",
    "    if (word not in stopwords_english and\n",
    "        word not in string.punctuation):\n",
    "      stem_word = stemmer.stem(word)    #stemming\n",
    "      tweet_clean.append(stem_word)\n",
    "\n",
    "\n",
    "  return tweet_clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7503b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tweets(tweets, ys):\n",
    "  ys_list = np.squeeze(ys).tolist()\n",
    "  freqs ={}\n",
    "\n",
    "  for y, tweet in zip(ys_list, tweets):\n",
    "    for word in process_tweet(tweet):\n",
    "      pair = (word, y)\n",
    "      if pair in freqs:\n",
    "        freqs[pair] +=1\n",
    "      else:\n",
    "        freqs[pair] = 1\n",
    "  \n",
    "  return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77840c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(freqs, word, label):\n",
    "  n = 0\n",
    "  pair = (word, label)\n",
    "  if pair in freqs:\n",
    "    n = freqs[pair]\n",
    "  return n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d953591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# splitting the data for training and testing \n",
    "#train_netu = all_netural_tweets[:44000]\n",
    "#test_netu = all_netural_tweets[44000:]\n",
    "\n",
    "\n",
    "train_pos = all_positive_tweets[:57800]\n",
    "test_pos = all_positive_tweets[57800:]\n",
    "\n",
    "train_neg = all_negative_tweets[:28408]\n",
    "test_neg = all_negative_tweets[28408:]\n",
    "\n",
    "\n",
    "train_x = train_pos + train_neg\n",
    "test_x = test_pos + test_neg\n",
    "print(type(train_x))\n",
    "\n",
    "# numpy array for the labels in the training set\n",
    "train_y = np.append(np.ones((len(train_pos))), np.zeros((len(train_neg))))\n",
    "print((train_y))\n",
    "test_y = np.append(np.ones((len(test_pos))), np.zeros((len(test_neg))))\n",
    "print(type(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd269737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a frequency dictionary\n",
    "freqs = count_tweets(train_x, train_y)\n",
    "#print(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e52cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(freqs, train_x, train_y):\n",
    "  logliklihood = {}\n",
    "  logprior = 0\n",
    "\n",
    "  # calculate V, number of unique words in the vocabulary\n",
    "  vocab = set([pair[0] for pair in freqs.keys()])\n",
    "  V = len(vocab)\n",
    "\n",
    "  ## Calculate N_pos, N_neg, V_pos, V_neg\n",
    "  # N_pos : total number of positive words\n",
    "  # N_neg : total number of negative words\n",
    "  # V_pos : total number of unique positive words\n",
    "  # V_neg : total number of unique negative words\n",
    "\n",
    "  N_pos = N_neg = V_pos = V_neg = 0\n",
    "  for pair in freqs.keys():\n",
    "    if pair[1]>0:\n",
    "      V_pos +=1\n",
    "      N_pos += freqs[pair]\n",
    "    else:\n",
    "      V_neg +=1\n",
    "      N_neg += freqs[pair]\n",
    "\n",
    "  # Number of Documents (tweets)\n",
    "  D = len(train_y)\n",
    "\n",
    "  # D_pos, number of positive documnets\n",
    "  D_pos = len(list(filter(lambda x: x>0, train_y)))\n",
    "\n",
    "  # D_neg, number of negative documnets\n",
    "  D_neg = len(list(filter(lambda x: x<=0, train_y)))\n",
    "\n",
    "  # calculate the logprior\n",
    "  logprior = np.log(D_pos) - np.log(D_neg)\n",
    "\n",
    "  for word in vocab:\n",
    "    freqs_pos = lookup(freqs, word, 1)\n",
    "    freqs_neg = lookup(freqs, word, 0)\n",
    "\n",
    "    # calculte the probability of each word being positive and negative\n",
    "    p_w_pos = (freqs_pos+1)/(N_pos+V)\n",
    "    p_w_neg = (freqs_neg+1)/(N_neg+V)\n",
    "\n",
    "    logliklihood[word] = np.log(p_w_pos/p_w_neg)\n",
    "  \n",
    "  return logprior, logliklihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45683af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7103179800375461\n",
      "61114\n"
     ]
    }
   ],
   "source": [
    "logprior, loglikelihood = train_naive_bayes(freqs, train_x, train_y)\n",
    "print(logprior)\n",
    "print(len(loglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff4f1aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict(tweet, logprior, loglikelihood):\n",
    "  word_l = process_tweet(tweet)\n",
    "  p = 0\n",
    "  p+=logprior\n",
    "\n",
    "  for word in word_l:\n",
    "    if word in loglikelihood:\n",
    "      p+=loglikelihood[word]\n",
    "    \n",
    "    #if (p > 1):\n",
    "     #   return \"Positive\"\n",
    "        # print(\"p is smaller\")\n",
    "    #elif (p < -0.1):\n",
    "     #    return \"Negative\"\n",
    "        # print(\"p is neutral\")\n",
    "  \n",
    "\n",
    "  return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8972f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets = [\"the food is good\",\"the food is great\",\"this is my house\", \"bring me food\", \"the food bad\", \"thank you for this amazing meal.\",\"i love this food\"]\n",
    "#for tweet in tweets:\n",
    "#    p=naive_bayes_predict(tweet, logprior,loglikelihood)\n",
    "#    if(p>1):\n",
    "#        print('\\033[92m')\n",
    "#        print(f'{tweet} :: Positive sentiment ({p:.2f})')\n",
    "#    elif(p<-0.1):\n",
    "#        print('\\033[91m')\n",
    "#        print(f'{tweet} :: Negative sentiment ({p:.2f})')\n",
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d347597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://192.168.1.65:4444/ (Press CTRL+C to quit)\n",
      "192.168.1.65 - - [28/Apr/2023 22:09:40] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.65 - - [28/Apr/2023 22:09:40] \"GET /css.css HTTP/1.1\" 404 -\n",
      "192.168.1.65 - - [28/Apr/2023 22:10:14] \"POST /result HTTP/1.1\" 200 -\n",
      "192.168.1.65 - - [28/Apr/2023 22:10:14] \"GET /css.css HTTP/1.1\" 404 -\n",
      "192.168.1.65 - - [28/Apr/2023 22:11:04] \"POST /result HTTP/1.1\" 200 -\n",
      "192.168.1.65 - - [28/Apr/2023 22:11:04] \"GET /css.css HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "@app.route('/result', methods=['POST'])\n",
    "def result():\n",
    "    if request.method == 'POST':\n",
    "        tweet = request.form['tweet']\n",
    "        prediction = naive_bayes_predict(tweet, logprior, loglikelihood)\n",
    "        \n",
    "        if(prediction > 0.1):\n",
    "            result = \"Positive\"\n",
    "      \n",
    "        else:\n",
    "            result = \"Negative\"\n",
    "            \n",
    "        return render_template(\"result.html\", prediction=result, name=tweet)\n",
    "    else:\n",
    "        return render_template(\"result.html\", prediction=result, name=tweet)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=False, host='0.0.0.0', port=4444)  # use debug = False for jupyter notebook\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
